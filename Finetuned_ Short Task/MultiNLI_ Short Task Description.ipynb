{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultiNLI: Short Task Description.ipynb","provenance":[{"file_id":"1U9zwEOx9pAMosmVvIQyB2Uk_qciUXksC","timestamp":1650415972619},{"file_id":"1u9YoxpPF4WDUip5qJfjMXvR84hwxah2a","timestamp":1650414009023}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIybZsj3VZUs","executionInfo":{"status":"ok","timestamp":1652478132705,"user_tz":240,"elapsed":969,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"ba05c6c6-6e6d-44cb-f8cc-da0d0bed6846"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FyK8YR5fJYDy","executionInfo":{"status":"ok","timestamp":1652478135774,"user_tz":240,"elapsed":3072,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"07fcca91-e449-4fda-a1f4-a3269508ce81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.7/dist-packages (2.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.0.53)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.1.96)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n","Fri May 13 21:42:15 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!pip install transformers==2.9.0\n","!nvidia-smi"]},{"cell_type":"code","source":["import random\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    AdamW,\n","    T5ForConditionalGeneration,\n","    T5Tokenizer,\n","    get_linear_schedule_with_warmup\n",")\n","def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","set_seed(42)"],"metadata":{"id":"moYr8VxVJaOv","executionInfo":{"status":"ok","timestamp":1652478139171,"user_tz":240,"elapsed":3401,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","t5_model = T5ForConditionalGeneration.from_pretrained('drive/MyDrive/outputs_new/model_files')"],"metadata":{"id":"SA67kT1vJeX2","executionInfo":{"status":"ok","timestamp":1652478145596,"user_tz":240,"elapsed":6430,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# optimizer\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in t5_model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","    {\n","        \"params\": [p for n, p in t5_model.named_parameters() if any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-4, eps=1e-8)"],"metadata":{"id":"UP3cO2USJhDd","executionInfo":{"status":"ok","timestamp":1652478145597,"user_tz":240,"elapsed":6,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["true_false_adjective_tuples = [\n","                               ((\"Can you lend me some money?\",\t\"I'm completely broke until payday.\"), \"no\"), \n","                               ((\"Do you think he did the theft?\",\t\"He is as innocent as a lamb\"), \"no\"),\n","                               ((\"Are you sure you want the spoiler\",\t\"haha sure. by the time, I get to it; I will forget the details, only knowing that it's touching at the end\"),\"yes\"),\n","                               ((\"Does tomorrow afternoon work for you?\",\t\"Yeah tomorrow afternoon works for me.\"),\t\"yes\"),\n","                               ((\"oh wow, Cuban cigar? I've never smoke before\",\t\"This one is actually from Peru, which is more my taste.\"),\t\"no\"),\n","                               ((\"Are you sending them an invitation?\",\t\"Certainly.\"),\t\"yes\"),\n","                               ((\"You, uh, you don't want to go for a ride, do you?\",\t\"Is it safe?\"),\t'yes'),\n","                               ((\"Have you ever made them yourself?\",\t\"no. only eat them\"),\t\"no\"),\n","                               ((\"Have you seen my watch?\",\t\"I will take a look for it around my house.\"),\t\"no\"),\n","                               ((\"You don't look normal. Are you all right?\", \"I have a headache.\"),\t\"no\"),\n","                               ((\"any improvements in your marathon time?\",\t\"No, only a few minutes. I still find it difficult to run long races\"),\t\"no\"),\n","                               ((\"do you live near San Mateo?\",\t\"no, but I'm willing to drive for good ramen\"),\t\"no\"),\n","                               ((\"Can he play the violin?\",\t\"Can a pig fly?\"),\t\"no\"),\n","                               ((\"Aren't you scared?\", \"Sometimes.\"),\t\"yes\")\n","]"],"metadata":{"id":"N1Na9ty4Jkgg","executionInfo":{"status":"ok","timestamp":1652478145597,"user_tz":240,"elapsed":5,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["t5_model.train()\n","\n","epochs = 10\n","\n","for epoch in range(epochs):\n","  print (\"epoch \",epoch)\n","  for input,output in true_false_adjective_tuples:\n","    input_sent = \"Determine the implicature: \"+input[0] + input[1]+ \" </s>\"\n","    ouput_sent = output+\" </s>\"\n","\n","    tokenized_inp = tokenizer.encode_plus(input_sent,  max_length=96, pad_to_max_length=True,return_tensors=\"pt\")\n","    tokenized_output = tokenizer.encode_plus(ouput_sent, max_length=96, pad_to_max_length=True,return_tensors=\"pt\")\n","\n","\n","    input_ids  = tokenized_inp[\"input_ids\"]\n","    attention_mask = tokenized_inp[\"attention_mask\"]\n","\n","    lm_labels= tokenized_output[\"input_ids\"]\n","    decoder_attention_mask=  tokenized_output[\"attention_mask\"]\n","\n","\n","    # the forward function automatically creates the correct decoder_input_ids\n","    output = t5_model(input_ids=input_ids, lm_labels=lm_labels,decoder_attention_mask=decoder_attention_mask,attention_mask=attention_mask)\n","    loss = output[0]\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()"],"metadata":{"id":"tF4B9jloJnRa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652478460054,"user_tz":240,"elapsed":314461,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"33f79dee-92d6-4026-a236-1d437518b4fd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"]},{"output_type":"stream","name":"stdout","text":["epoch  1\n","epoch  2\n","epoch  3\n","epoch  4\n","epoch  5\n","epoch  6\n","epoch  7\n","epoch  8\n","epoch  9\n"]}]},{"cell_type":"code","source":["import csv\n","file = csv.reader(open('testing.csv'))\n","correct = 0\n","wrong = 0\n","total = 0\n","tp = 0\n","tn = 0\n","fp = 0\n","fn = 0\n","for line in file:\n","  test_sent = \"Determine the implicature: \" + line[0] + \"</s>\"\n","  test_tokenized = tokenizer.encode_plus(test_sent, return_tensors=\"pt\")\n","\n","  test_input_ids  = test_tokenized[\"input_ids\"]\n","  test_attention_mask = test_tokenized[\"attention_mask\"]\n","\n","  t5_model.eval()\n","  beam_outputs = t5_model.generate(\n","      input_ids=test_input_ids,attention_mask=test_attention_mask,\n","      max_length=64,\n","      early_stopping=True,\n","      num_beams=10,\n","      num_return_sequences=1,\n","      no_repeat_ngram_size=2\n","  )\n","\n","  for beam_output in beam_outputs:\n","      sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n","      print (sent, line[1])\n","      if sent == line[1]:\n","        correct += 1\n","      else:\n","        wrong += 1\n","      if sent == 'yes' and line[1] == 'yes':\n","        tp += 1\n","      elif sent == 'yes' and line[1] == 'no':\n","        fp += 1\n","      elif sent == 'no' and line[1] == 'yes':\n","        fn += 1\n","      elif sent == 'no' and line[1] == 'no':\n","        tn += 1\n","      print(correct, wrong)\n","  print(\"\")\n","  total += 1\n","  print(total)"],"metadata":{"id":"KDA9GhwRzwMp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652478525871,"user_tz":240,"elapsed":65836,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"1363d786-3ed6-4f39-961f-920ed6bf9622"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:1432: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beam_id = beam_token_id // vocab_size\n"]},{"output_type":"stream","name":"stdout","text":["no no\n","1 0\n","\n","1\n","yes no\n","1 1\n","\n","2\n","no no\n","2 1\n","\n","3\n","yes no\n","2 2\n","\n","4\n","yes no\n","2 3\n","\n","5\n","yes yes\n","3 3\n","\n","6\n","yes yes\n","4 3\n","\n","7\n","yes no\n","4 4\n","\n","8\n","yes yes\n","5 4\n","\n","9\n","yes yes\n","6 4\n","\n","10\n","yes yes\n","7 4\n","\n","11\n","yes no\n","7 5\n","\n","12\n","yes no\n","7 6\n","\n","13\n","no no\n","8 6\n","\n","14\n","yes no\n","8 7\n","\n","15\n","yes yes\n","9 7\n","\n","16\n","yes yes\n","10 7\n","\n","17\n","yes yes\n","11 7\n","\n","18\n","yes yes\n","12 7\n","\n","19\n","yes yes\n","13 7\n","\n","20\n","yes yes\n","14 7\n","\n","21\n","yes yes\n","15 7\n","\n","22\n","no no\n","16 7\n","\n","23\n","yes yes\n","17 7\n","\n","24\n","yes no\n","17 8\n","\n","25\n","yes yes\n","18 8\n","\n","26\n","no no\n","19 8\n","\n","27\n","yes yes\n","20 8\n","\n","28\n","yes yes\n","21 8\n","\n","29\n","yes yes\n","22 8\n","\n","30\n","no yes\n","22 9\n","\n","31\n","yes yes\n","23 9\n","\n","32\n","yes yes\n","24 9\n","\n","33\n","yes no\n","24 10\n","\n","34\n","no yes\n","24 11\n","\n","35\n","no no\n","25 11\n","\n","36\n","yes yse\n","25 12\n","\n","37\n","yes yes\n","26 12\n","\n","38\n","yes yes\n","27 12\n","\n","39\n","yes yes\n","28 12\n","\n","40\n","yes no\n","28 13\n","\n","41\n","no no\n","29 13\n","\n","42\n","no no\n","30 13\n","\n","43\n","yes no\n","30 14\n","\n","44\n","no no\n","31 14\n","\n","45\n","yes yes\n","32 14\n","\n","46\n","yes yes\n","33 14\n","\n","47\n","yes yes\n","34 14\n","\n","48\n","yes no\n","34 15\n","\n","49\n","yes yes\n","35 15\n","\n","50\n","yes yes\n","36 15\n","\n","51\n","yes yes\n","37 15\n","\n","52\n","no yes\n","37 16\n","\n","53\n","yes yes\n","38 16\n","\n","54\n","yes yes\n","39 16\n","\n","55\n","yes yes\n","40 16\n","\n","56\n","yes yes\n","41 16\n","\n","57\n","yes yes\n","42 16\n","\n","58\n","yes no\n","42 17\n","\n","59\n","yes yes\n","43 17\n","\n","60\n","yes yes\n","44 17\n","\n","61\n","yes yes\n","45 17\n","\n","62\n","yes yes\n","46 17\n","\n","63\n","yes no\n","46 18\n","\n","64\n","yes no\n","46 19\n","\n","65\n","yes yes\n","47 19\n","\n","66\n","yes yes\n","48 19\n","\n","67\n","yes yes\n","49 19\n","\n","68\n","yes yes\n","50 19\n","\n","69\n","yes yes\n","51 19\n","\n","70\n","no no\n","52 19\n","\n","71\n","yes no\n","52 20\n","\n","72\n","yes yes\n","53 20\n","\n","73\n","no no\n","54 20\n","\n","74\n","yes yes\n","55 20\n","\n","75\n","no no\n","56 20\n","\n","76\n","yes yes\n","57 20\n","\n","77\n","yes yes\n","58 20\n","\n","78\n","yes yes\n","59 20\n","\n","79\n","yes yes\n","60 20\n","\n","80\n","yes no\n","60 21\n","\n","81\n","no yes\n","60 22\n","\n","82\n","yes no\n","60 23\n","\n","83\n","yes yes\n","61 23\n","\n","84\n","yes yes\n","62 23\n","\n","85\n","no yes\n","62 24\n","\n","86\n","yes yes\n","63 24\n","\n","87\n","yes yes\n","64 24\n","\n","88\n","yes no\n","64 25\n","\n","89\n","yes yes\n","65 25\n","\n","90\n","yes yes\n","66 25\n","\n","91\n","yes yes\n","67 25\n","\n","92\n","yes yes\n","68 25\n","\n","93\n","yes yes\n","69 25\n","\n","94\n","yes yes\n","70 25\n","\n","95\n","no no\n","71 25\n","\n","96\n","yes yes\n","72 25\n","\n","97\n","yes yes\n","73 25\n","\n","98\n","yes yes\n","74 25\n","\n","99\n","yes yes\n","75 25\n","\n","100\n","yes no\n","75 26\n","\n","101\n","no no\n","76 26\n","\n","102\n","yes no\n","76 27\n","\n","103\n","yes no\n","76 28\n","\n","104\n","no no\n","77 28\n","\n","105\n","yes yes\n","78 28\n","\n","106\n","no no\n","79 28\n","\n","107\n","yes yes\n","80 28\n","\n","108\n","no no\n","81 28\n","\n","109\n","no no\n","82 28\n","\n","110\n","yes yes\n","83 28\n","\n","111\n","yes yes\n","84 28\n","\n","112\n","yes yes\n","85 28\n","\n","113\n","yes yes\n","86 28\n","\n","114\n","no no\n","87 28\n","\n","115\n","no no\n","88 28\n","\n","116\n","yes no\n","88 29\n","\n","117\n","yes no\n","88 30\n","\n","118\n","no no\n","89 30\n","\n","119\n","yes yes\n","90 30\n","\n","120\n","yes yes\n","91 30\n","\n","121\n","yes no\n","91 31\n","\n","122\n","no no\n","92 31\n","\n","123\n","yes yes\n","93 31\n","\n","124\n","yes yes\n","94 31\n","\n","125\n","no no\n","95 31\n","\n","126\n","no no\n","96 31\n","\n","127\n","yes yes\n","97 31\n","\n","128\n","yes no\n","97 32\n","\n","129\n","yes no\n","97 33\n","\n","130\n","yes no\n","97 34\n","\n","131\n","yes no\n","97 35\n","\n","132\n","yes yes\n","98 35\n","\n","133\n","no no\n","99 35\n","\n","134\n","yes yes\n","100 35\n","\n","135\n","yes yes\n","101 35\n","\n","136\n","yes yes\n","102 35\n","\n","137\n","yes no\n","102 36\n","\n","138\n","no no\n","103 36\n","\n","139\n","yes no\n","103 37\n","\n","140\n","yes yes\n","104 37\n","\n","141\n","no no\n","105 37\n","\n","142\n","no no\n","106 37\n","\n","143\n","yes yes\n","107 37\n","\n","144\n","yes yes\n","108 37\n","\n","145\n","yes yes\n","109 37\n","\n","146\n","yes yes\n","110 37\n","\n","147\n","no no\n","111 37\n","\n","148\n","no yes\n","111 38\n","\n","149\n","no no\n","112 38\n","\n","150\n","yes yes\n","113 38\n","\n","151\n","yes no\n","113 39\n","\n","152\n","no no\n","114 39\n","\n","153\n","yes yes\n","115 39\n","\n","154\n","yes yes\n","116 39\n","\n","155\n","yes yes\n","117 39\n","\n","156\n","yes yes\n","118 39\n","\n","157\n","yes no\n","118 40\n","\n","158\n","yes no\n","118 41\n","\n","159\n","yes yes\n","119 41\n","\n","160\n","no no\n","120 41\n","\n","161\n","no yes\n","120 42\n","\n","162\n","yes no\n","120 43\n","\n","163\n","yes yes\n","121 43\n","\n","164\n","yes no\n","121 44\n","\n","165\n","yes yes\n","122 44\n","\n","166\n","yes no\n","122 45\n","\n","167\n","yes yes\n","123 45\n","\n","168\n","no yes\n","123 46\n","\n","169\n","yes yes\n","124 46\n","\n","170\n","no no\n","125 46\n","\n","171\n","yes yes\n","126 46\n","\n","172\n","yes yes\n","127 46\n","\n","173\n","yes yes\n","128 46\n","\n","174\n","no no\n","129 46\n","\n","175\n","yes no\n","129 47\n","\n","176\n","yes yes\n","130 47\n","\n","177\n","yes yes\n","131 47\n","\n","178\n","yes yes\n","132 47\n","\n","179\n","no yes\n","132 48\n","\n","180\n","no no\n","133 48\n","\n","181\n","yes yes\n","134 48\n","\n","182\n"]}]},{"cell_type":"code","source":["print(\"Correct Predictions: \",correct)\n","print(\"Incorrect Predictions:\", wrong)\n","print(\"Accuracy:\", correct/total)"],"metadata":{"id":"ZsFihtkm8E4_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652478525872,"user_tz":240,"elapsed":25,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"201b5382-2ae9-4ef5-eae6-70da6e92f43b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Correct Predictions:  134\n","Incorrect Predictions: 48\n","Accuracy: 0.7362637362637363\n"]}]},{"cell_type":"code","source":["recall = tp / (tp + fn)\n","precision = tp / (tp + fp)\n","f1_score = (2 * recall * precision) / (recall + precision) \n","print(\"Recall: \", recall)\n","print(\"Precision: \", precision)\n","print(\"F1 score: \", f1_score)"],"metadata":{"id":"a2Nfvlhg8Q7U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652478525873,"user_tz":240,"elapsed":20,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"6a1563d9-3cec-4a15-c859-53298d144a4c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Recall:  0.9166666666666666\n","Precision:  0.7226277372262774\n","F1 score:  0.8081632653061225\n"]}]}]}