{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Squad: Short Task Description.ipynb","provenance":[{"file_id":"1U9zwEOx9pAMosmVvIQyB2Uk_qciUXksC","timestamp":1650415972619},{"file_id":"1u9YoxpPF4WDUip5qJfjMXvR84hwxah2a","timestamp":1650414009023}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIybZsj3VZUs","executionInfo":{"status":"ok","timestamp":1652477539164,"user_tz":240,"elapsed":1052,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"ce56036d-a54c-4fd3-95ce-ca419ed099b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FyK8YR5fJYDy","executionInfo":{"status":"ok","timestamp":1652477542566,"user_tz":240,"elapsed":3407,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"85e0fac0-680c-42a9-af0f-753480db9e3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.7/dist-packages (2.9.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (1.21.6)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (3.6.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.0.53)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n","Fri May 13 21:32:22 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!pip install transformers==2.9.0\n","!nvidia-smi"]},{"cell_type":"code","source":["import random\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    AdamW,\n","    T5ForConditionalGeneration,\n","    T5Tokenizer,\n","    get_linear_schedule_with_warmup\n",")\n","def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","set_seed(42)"],"metadata":{"id":"moYr8VxVJaOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","t5_model = T5ForConditionalGeneration.from_pretrained('drive/MyDrive/outputs/model_files')"],"metadata":{"id":"SA67kT1vJeX2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# optimizer\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in t5_model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","    {\n","        \"params\": [p for n, p in t5_model.named_parameters() if any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-4, eps=1e-8)"],"metadata":{"id":"UP3cO2USJhDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["true_false_adjective_tuples = [\n","                               ((\"Can you lend me some money?\",\t\"I'm completely broke until payday.\"), \"no\"), \n","                               ((\"Do you think he did the theft?\",\t\"He is as innocent as a lamb\"), \"no\"),\n","                               ((\"Are you sure you want the spoiler\",\t\"haha sure. by the time, I get to it; I will forget the details, only knowing that it's touching at the end\"),\"yes\"),\n","                               ((\"Does tomorrow afternoon work for you?\",\t\"Yeah tomorrow afternoon works for me.\"),\t\"yes\"),\n","                               ((\"oh wow, Cuban cigar? I've never smoke before\",\t\"This one is actually from Peru, which is more my taste.\"),\t\"no\"),\n","                               ((\"Are you sending them an invitation?\",\t\"Certainly.\"),\t\"yes\"),\n","                               ((\"You, uh, you don't want to go for a ride, do you?\",\t\"Is it safe?\"),\t'yes'),\n","                               ((\"Have you ever made them yourself?\",\t\"no. only eat them\"),\t\"no\"),\n","                               ((\"Have you seen my watch?\",\t\"I will take a look for it around my house.\"),\t\"no\"),\n","                               ((\"You don't look normal. Are you all right?\", \"I have a headache.\"),\t\"no\"),\n","                               ((\"any improvements in your marathon time?\",\t\"No, only a few minutes. I still find it difficult to run long races\"),\t\"no\"),\n","                               ((\"do you live near San Mateo?\",\t\"no, but I'm willing to drive for good ramen\"),\t\"no\"),\n","                               ((\"Can he play the violin?\",\t\"Can a pig fly?\"),\t\"no\"),\n","                               ((\"Aren't you scared?\", \"Sometimes.\"),\t\"yes\")\n","]"],"metadata":{"id":"N1Na9ty4Jkgg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t5_model.train()\n","\n","epochs = 10\n","\n","for epoch in range(epochs):\n","  print (\"epoch \",epoch)\n","  for input,output in true_false_adjective_tuples:\n","    input_sent = \"Determine the implicature: \" + input[0] + \" \" + input[1]+ \" </s>\"\n","    ouput_sent = output+\" </s>\"\n","\n","    tokenized_inp = tokenizer.encode_plus(input_sent,  max_length=96, pad_to_max_length=True,return_tensors=\"pt\")\n","    tokenized_output = tokenizer.encode_plus(ouput_sent, max_length=96, pad_to_max_length=True,return_tensors=\"pt\")\n","\n","\n","    input_ids  = tokenized_inp[\"input_ids\"]\n","    attention_mask = tokenized_inp[\"attention_mask\"]\n","\n","    lm_labels= tokenized_output[\"input_ids\"]\n","    decoder_attention_mask=  tokenized_output[\"attention_mask\"]\n","\n","\n","    # the forward function automatically creates the correct decoder_input_ids\n","    output = t5_model(input_ids=input_ids, lm_labels=lm_labels,decoder_attention_mask=decoder_attention_mask,attention_mask=attention_mask)\n","    loss = output[0]\n","\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tF4B9jloJnRa","outputId":"be9d9866-cd7b-4490-e509-d5a75ccf22b3","executionInfo":{"status":"ok","timestamp":1652477917106,"user_tz":240,"elapsed":357998,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch  0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"]},{"output_type":"stream","name":"stdout","text":["epoch  1\n","epoch  2\n","epoch  3\n","epoch  4\n","epoch  5\n","epoch  6\n","epoch  7\n","epoch  8\n","epoch  9\n"]}]},{"cell_type":"code","source":["import csv\n","file = csv.reader(open('testing.csv'))\n","correct = 0\n","wrong = 0\n","total = 0\n","tp = 0\n","tn = 0\n","fp = 0\n","fn = 0\n","for line in file:\n","  test_sent = \"Determine the implicature: \" + line[0] + \"</s>\"\n","  test_tokenized = tokenizer.encode_plus(test_sent, return_tensors=\"pt\")\n","\n","  test_input_ids  = test_tokenized[\"input_ids\"]\n","  test_attention_mask = test_tokenized[\"attention_mask\"]\n","\n","  t5_model.eval()\n","  beam_outputs = t5_model.generate(\n","      input_ids=test_input_ids,attention_mask=test_attention_mask,\n","      max_length=64,\n","      early_stopping=True,\n","      num_beams=10,\n","      num_return_sequences=1,\n","      no_repeat_ngram_size=2\n","  )\n","\n","  for beam_output in beam_outputs:\n","      sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n","      print (sent, line[1])\n","      if sent == line[1]:\n","        correct += 1\n","      else:\n","        wrong += 1\n","      if sent == 'yes' and line[1] == 'yes':\n","        tp += 1\n","      elif sent == 'yes' and line[1] == 'no':\n","        fp += 1\n","      elif sent == 'no' and line[1] == 'yes':\n","        fn += 1\n","      elif sent == 'no' and line[1] == 'no':\n","        tn += 1\n","      print(correct, wrong)\n","  print(\"\")\n","  total += 1\n","  print(total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDA9GhwRzwMp","executionInfo":{"status":"ok","timestamp":1652477990462,"user_tz":240,"elapsed":73359,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"af7852fb-16a3-49e4-a0ee-60936e188dfc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py:1432: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beam_id = beam_token_id // vocab_size\n"]},{"output_type":"stream","name":"stdout","text":["no no\n","1 0\n","\n","1\n","yes no\n","1 1\n","\n","2\n","no no\n","2 1\n","\n","3\n","no no\n","3 1\n","\n","4\n","yes no\n","3 2\n","\n","5\n","yes yes\n","4 2\n","\n","6\n","no yes\n","4 3\n","\n","7\n","no no\n","5 3\n","\n","8\n","no yes\n","5 4\n","\n","9\n","yes yes\n","6 4\n","\n","10\n","yes yes\n","7 4\n","\n","11\n","yes no\n","7 5\n","\n","12\n","no no\n","8 5\n","\n","13\n","no no\n","9 5\n","\n","14\n","yes no\n","9 6\n","\n","15\n","yes yes\n","10 6\n","\n","16\n","no yes\n","10 7\n","\n","17\n","yes yes\n","11 7\n","\n","18\n","no yes\n","11 8\n","\n","19\n","yes yes\n","12 8\n","\n","20\n","yes yes\n","13 8\n","\n","21\n","yes yes\n","14 8\n","\n","22\n","no no\n","15 8\n","\n","23\n","yes yes\n","16 8\n","\n","24\n","no no\n","17 8\n","\n","25\n","yes yes\n","18 8\n","\n","26\n","no no\n","19 8\n","\n","27\n","no yes\n","19 9\n","\n","28\n","yes yes\n","20 9\n","\n","29\n","no yes\n","20 10\n","\n","30\n","no yes\n","20 11\n","\n","31\n","no yes\n","20 12\n","\n","32\n","yes yes\n","21 12\n","\n","33\n","no no\n","22 12\n","\n","34\n","no yes\n","22 13\n","\n","35\n","no no\n","23 13\n","\n","36\n","yes yse\n","23 14\n","\n","37\n","yes yes\n","24 14\n","\n","38\n","yes yes\n","25 14\n","\n","39\n","yes yes\n","26 14\n","\n","40\n","yes no\n","26 15\n","\n","41\n","no no\n","27 15\n","\n","42\n","no no\n","28 15\n","\n","43\n","no no\n","29 15\n","\n","44\n","no no\n","30 15\n","\n","45\n","no yes\n","30 16\n","\n","46\n","yes yes\n","31 16\n","\n","47\n","yes yes\n","32 16\n","\n","48\n","no no\n","33 16\n","\n","49\n","yes yes\n","34 16\n","\n","50\n","no yes\n","34 17\n","\n","51\n","yes yes\n","35 17\n","\n","52\n","no yes\n","35 18\n","\n","53\n","yes yes\n","36 18\n","\n","54\n","no yes\n","36 19\n","\n","55\n","yes yes\n","37 19\n","\n","56\n","no yes\n","37 20\n","\n","57\n","yes yes\n","38 20\n","\n","58\n","no no\n","39 20\n","\n","59\n","yes yes\n","40 20\n","\n","60\n","yes yes\n","41 20\n","\n","61\n","yes yes\n","42 20\n","\n","62\n","yes yes\n","43 20\n","\n","63\n","yes no\n","43 21\n","\n","64\n","no no\n","44 21\n","\n","65\n","yes yes\n","45 21\n","\n","66\n","yes yes\n","46 21\n","\n","67\n","yes yes\n","47 21\n","\n","68\n","yes yes\n","48 21\n","\n","69\n","yes yes\n","49 21\n","\n","70\n","no no\n","50 21\n","\n","71\n","no no\n","51 21\n","\n","72\n","yes yes\n","52 21\n","\n","73\n","yes no\n","52 22\n","\n","74\n","yes yes\n","53 22\n","\n","75\n","no no\n","54 22\n","\n","76\n","no yes\n","54 23\n","\n","77\n","yes yes\n","55 23\n","\n","78\n","no yes\n","55 24\n","\n","79\n","no yes\n","55 25\n","\n","80\n","no no\n","56 25\n","\n","81\n","no yes\n","56 26\n","\n","82\n","yes no\n","56 27\n","\n","83\n","yes yes\n","57 27\n","\n","84\n","no yes\n","57 28\n","\n","85\n","no yes\n","57 29\n","\n","86\n","no yes\n","57 30\n","\n","87\n","yes yes\n","58 30\n","\n","88\n","yes no\n","58 31\n","\n","89\n","yes yes\n","59 31\n","\n","90\n","yes yes\n","60 31\n","\n","91\n","yes yes\n","61 31\n","\n","92\n","yes yes\n","62 31\n","\n","93\n","no yes\n","62 32\n","\n","94\n","no yes\n","62 33\n","\n","95\n","no no\n","63 33\n","\n","96\n","yes yes\n","64 33\n","\n","97\n","no yes\n","64 34\n","\n","98\n","yes yes\n","65 34\n","\n","99\n","yes yes\n","66 34\n","\n","100\n","yes no\n","66 35\n","\n","101\n","no no\n","67 35\n","\n","102\n","yes no\n","67 36\n","\n","103\n","no no\n","68 36\n","\n","104\n","no no\n","69 36\n","\n","105\n","yes yes\n","70 36\n","\n","106\n","no no\n","71 36\n","\n","107\n","yes yes\n","72 36\n","\n","108\n","no no\n","73 36\n","\n","109\n","no no\n","74 36\n","\n","110\n","no yes\n","74 37\n","\n","111\n","yes yes\n","75 37\n","\n","112\n","yes yes\n","76 37\n","\n","113\n","yes yes\n","77 37\n","\n","114\n","yes no\n","77 38\n","\n","115\n","no no\n","78 38\n","\n","116\n","no no\n","79 38\n","\n","117\n","no no\n","80 38\n","\n","118\n","no no\n","81 38\n","\n","119\n","yes yes\n","82 38\n","\n","120\n","yes yes\n","83 38\n","\n","121\n","yes no\n","83 39\n","\n","122\n","no no\n","84 39\n","\n","123\n","yes yes\n","85 39\n","\n","124\n","yes yes\n","86 39\n","\n","125\n","no no\n","87 39\n","\n","126\n","no no\n","88 39\n","\n","127\n","yes yes\n","89 39\n","\n","128\n","no no\n","90 39\n","\n","129\n","no no\n","91 39\n","\n","130\n","yes no\n","91 40\n","\n","131\n","yes no\n","91 41\n","\n","132\n","yes yes\n","92 41\n","\n","133\n","no no\n","93 41\n","\n","134\n","yes yes\n","94 41\n","\n","135\n","yes yes\n","95 41\n","\n","136\n","yes yes\n","96 41\n","\n","137\n","no no\n","97 41\n","\n","138\n","no no\n","98 41\n","\n","139\n","yes no\n","98 42\n","\n","140\n","yes yes\n","99 42\n","\n","141\n","no no\n","100 42\n","\n","142\n","no no\n","101 42\n","\n","143\n","no yes\n","101 43\n","\n","144\n","yes yes\n","102 43\n","\n","145\n","yes yes\n","103 43\n","\n","146\n","yes yes\n","104 43\n","\n","147\n","no no\n","105 43\n","\n","148\n","no yes\n","105 44\n","\n","149\n","no no\n","106 44\n","\n","150\n","yes yes\n","107 44\n","\n","151\n","yes no\n","107 45\n","\n","152\n","yes no\n","107 46\n","\n","153\n","yes yes\n","108 46\n","\n","154\n","yes yes\n","109 46\n","\n","155\n","yes yes\n","110 46\n","\n","156\n","yes yes\n","111 46\n","\n","157\n","yes no\n","111 47\n","\n","158\n","yes no\n","111 48\n","\n","159\n","yes yes\n","112 48\n","\n","160\n","no no\n","113 48\n","\n","161\n","no yes\n","113 49\n","\n","162\n","yes no\n","113 50\n","\n","163\n","yes yes\n","114 50\n","\n","164\n","yes no\n","114 51\n","\n","165\n","no yes\n","114 52\n","\n","166\n","yes no\n","114 53\n","\n","167\n","yes yes\n","115 53\n","\n","168\n","no yes\n","115 54\n","\n","169\n","yes yes\n","116 54\n","\n","170\n","no no\n","117 54\n","\n","171\n","yes yes\n","118 54\n","\n","172\n","no yes\n","118 55\n","\n","173\n","yes yes\n","119 55\n","\n","174\n","no no\n","120 55\n","\n","175\n","yes no\n","120 56\n","\n","176\n","yes yes\n","121 56\n","\n","177\n","yes yes\n","122 56\n","\n","178\n","yes yes\n","123 56\n","\n","179\n","yes yes\n","124 56\n","\n","180\n","no no\n","125 56\n","\n","181\n","yes yes\n","126 56\n","\n","182\n"]}]},{"cell_type":"code","source":["print(\"Correct Predictions: \",correct)\n","print(\"Incorrect Predictions:\", wrong)\n","print(\"Accuracy:\", correct/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsFihtkm8E4_","executionInfo":{"status":"ok","timestamp":1652477990463,"user_tz":240,"elapsed":26,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"55581615-7ab5-4b4c-cd14-5d735ddaac6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Correct Predictions:  126\n","Incorrect Predictions: 56\n","Accuracy: 0.6923076923076923\n"]}]},{"cell_type":"code","source":["recall = tp / (tp + fn)\n","precision = tp / (tp + fp)\n","f1_score = (2 * recall * precision) / (recall + precision) \n","print(\"Recall: \", recall)\n","print(\"Precision: \", precision)\n","print(\"F1 score: \", f1_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2Nfvlhg8Q7U","executionInfo":{"status":"ok","timestamp":1652477990463,"user_tz":240,"elapsed":8,"user":{"displayName":"Mohini Anand","userId":"11239111325445757536"}},"outputId":"a70ca9d9-e345-4e39-84e9-7e9755828a5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recall:  0.7129629629629629\n","Precision:  0.7623762376237624\n","F1 score:  0.7368421052631577\n"]}]}]}